{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "import torch\n",
    "import cv2\n",
    "import glob\n",
    "import torch.utils.data as udata\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    return data/255.0 \n",
    "\n",
    "\n",
    "def Im2Patch(img, win, stride=1):\n",
    "    k = 0\n",
    "    endc = img.shape[0]\n",
    "    endw = img.shape[1]\n",
    "    endh = img.shape[2]\n",
    "    patch = img[:, 0 : endw - win + 0 + 1 : stride, 0 : endh - win + 0 + 1 : stride]\n",
    "    TotalPatNum = patch.shape[1] * patch.shape[2]\n",
    "    Y = np.zeros([endc, win * win, TotalPatNum], np.float32)\n",
    "    for i in range(win):\n",
    "        for j in range(win):\n",
    "            patch = img[\n",
    "                :, i : endw - win + i + 1 : stride, j : endh - win + j + 1 : stride\n",
    "            ]\n",
    "            Y[:, k, :] = np.array(patch[:]).reshape(endc, TotalPatNum)\n",
    "            k += 1\n",
    "    return Y.reshape([endc, win, win, TotalPatNum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_kaiming(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def batch_PSNR(img1, img2, scale):\n",
    "    img1 = img1.cpu().detach().numpy()\n",
    "    img2 = img2.cpu().detach().numpy()\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 1.0\n",
    "    return 20 * np.log10(PIXEL_MAX / np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(data, aug_type):\n",
    "    if aug_type == 1:\n",
    "        return np.fliplr(data)\n",
    "    elif aug_type == 2:\n",
    "        return np.flipud(data)\n",
    "    elif aug_type == 3:\n",
    "        return np.rot90(data, k=1)\n",
    "    elif aug_type == 4:\n",
    "        return np.rot90(data, k=2)\n",
    "    elif aug_type == 5:\n",
    "        return np.rot90(data, k=3)\n",
    "    elif aug_type == 6:\n",
    "        return np.fliplr(np.rot90(data, k=1))\n",
    "    elif aug_type == 7:\n",
    "        return np.flipud(np.rot90(data, k=1))\n",
    "    elif aug_type == 8:\n",
    "        return np.fliplr(np.flipud(data))\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_path, patch_size, stride, aug_times=1):\n",
    "    print(\"Process training data\")\n",
    "    scales = [1, 0.9, 0.8, 0.7]\n",
    "    files = glob.glob(os.path.join(data_path, \"train\", \"*.png\"))\n",
    "    files.sort()\n",
    "    h5f = h5py.File(\"train.h5\", \"w\")\n",
    "    train_num = 0\n",
    "    for i in range(len(files)):\n",
    "        img = cv2.imread(files[i])\n",
    "        h, w, c = img.shape\n",
    "        for k in range(len(scales)):\n",
    "            Img = cv2.resize(\n",
    "                img,\n",
    "                (int(h * scales[k]), int(w * scales[k])),\n",
    "                interpolation=cv2.INTER_CUBIC,\n",
    "            )\n",
    "            Img = np.expand_dims(Img[:, :, 0].copy(), 0)\n",
    "            Img = np.float32(normalize(Img))\n",
    "            patches = Im2Patch(Img, win=patch_size, stride=stride)\n",
    "            print(\n",
    "                f\"File: {files[i]} Scale {scales[k]:.1f} # samples: {patches.shape[3] * aug_times}\"\n",
    "            )\n",
    "            for n in range(patches.shape[3]):\n",
    "                data = patches[:, :, :, n].copy()\n",
    "                h5f.create_dataset(str(train_num), data=data)\n",
    "                train_num += 1\n",
    "                for m in range(aug_times - 1):\n",
    "                    data_aug = data_augmentation(data, np.random.randint(1, 8))\n",
    "                    h5f.create_dataset(str(train_num) + f\"_aug_{m+1}\", data=data_aug)\n",
    "                    train_num += 1\n",
    "    h5f.close()\n",
    "\n",
    "    # Validation data\n",
    "    print(\"\\nProcess validation data\")\n",
    "    files = glob.glob(os.path.join(data_path, \"Set12\", \"*.png\"))\n",
    "    files.sort()\n",
    "    h5f = h5py.File(\"val.h5\", \"w\")\n",
    "    val_num = 0\n",
    "    for i in range(len(files)):\n",
    "        print(f\"File: {files[i]}\")\n",
    "        img = cv2.imread(files[i])\n",
    "        img = np.expand_dims(img[:, :, 0], 0)\n",
    "        img = np.float32(normalize(img))\n",
    "        h5f.create_dataset(str(val_num), data=img)\n",
    "        val_num += 1\n",
    "    h5f.close()\n",
    "    print(f\"Training set, # samples {train_num}\\n\")\n",
    "    print(f\"Validation set, # samples {val_num}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(udata.Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            self.h5f = h5py.File(\"train.h5\", \"r\")\n",
    "        else:\n",
    "            self.h5f = h5py.File(\"val.h5\", \"r\")\n",
    "        self.keys = list(self.h5f.keys())\n",
    "        random.shuffle(self.keys)\n",
    "        self.h5f.close()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            h5f = h5py.File(\"train.h5\", \"r\")\n",
    "        else:\n",
    "            h5f = h5py.File(\"val.h5\", \"r\")\n",
    "        key = self.keys[index]\n",
    "        data = np.array(h5f[key])\n",
    "        h5f.close()\n",
    "        return torch.Tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, channels, num_of_layers=17):\n",
    "        super(DnCNN, self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        features = 64\n",
    "        layers = [\n",
    "            nn.Conv2d(\n",
    "                in_channels=channels,\n",
    "                out_channels=features,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        for _ in range(num_of_layers - 2):\n",
    "            layers.extend(\n",
    "                [\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=features,\n",
    "                        out_channels=features,\n",
    "                        kernel_size=kernel_size,\n",
    "                        padding=padding,\n",
    "                        bias=False,\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(features),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                ]\n",
    "            )\n",
    "        layers.append(\n",
    "            nn.Conv2d(\n",
    "                in_channels=features,\n",
    "                out_channels=channels,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=padding,\n",
    "                bias=False,\n",
    "            )\n",
    "        )\n",
    "        self.dncnn = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dncnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class DenoisingDataset(Dataset):\n",
    "    def __init__(self, noisy_dir, clean_dir, transform=None):\n",
    "        self.noisy_dir = noisy_dir\n",
    "        self.clean_dir = clean_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Get list of noisy and clean image files\n",
    "        self.noisy_images = sorted(os.listdir(noisy_dir))\n",
    "        self.clean_images = sorted(os.listdir(clean_dir))\n",
    "\n",
    "        # Ensure same number of noisy and clean images\n",
    "        if len(self.noisy_images) != len(self.clean_images):\n",
    "            raise ValueError(\"The number of noisy and clean images must be the same.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.noisy_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        noisy_image_path = os.path.join(self.noisy_dir, self.noisy_images[idx])\n",
    "        clean_image_path = os.path.join(self.clean_dir, self.clean_images[idx])\n",
    "\n",
    "        noisy_image = Image.open(noisy_image_path)\n",
    "        clean_image = Image.open(clean_image_path)\n",
    "\n",
    "        if self.transform:\n",
    "            noisy_image = self.transform(noisy_image)\n",
    "            clean_image = self.transform(clean_image)\n",
    "\n",
    "        return noisy_image, clean_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from torchvision import  transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def train_dncnn(\n",
    "    preprocess=False,\n",
    "    batch_size=128,\n",
    "    num_of_layers=17,\n",
    "    epochs=50,\n",
    "    lr=1e-3,\n",
    "    milestone=30,\n",
    "    noiseL=25,\n",
    "    val_noiseL=25,\n",
    "    logdir=\"logs\",\n",
    "):\n",
    "    if preprocess:\n",
    "        prepare_data(\"data\", patch_size=40, stride=10, aug_times=1)\n",
    "\n",
    "    print(\"Loading dataset ...\")\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((224, 224)),  # Adjust to your model's input size\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Directory paths\n",
    "    train_noisy_dir = (\n",
    "        \"/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/train/noisy\"\n",
    "    )\n",
    "    train_clean_dir = (\n",
    "        \"/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/train/clean\"\n",
    "    )\n",
    "    valid_noisy_dir = \"/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/valid/noisy\"  # Add validation directories if you have them\n",
    "    valid_clean_dir = (\n",
    "        \"/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/valid/clean\"\n",
    "    )\n",
    "\n",
    "    # Load datasets\n",
    "    dataset_train = DenoisingDataset(\n",
    "        noisy_dir=train_noisy_dir, clean_dir=train_clean_dir, transform=transform\n",
    "    )\n",
    "    dataset_val = DenoisingDataset(\n",
    "        noisy_dir=valid_noisy_dir, clean_dir=valid_clean_dir, transform=transform\n",
    "    )\n",
    "    loader_train = DataLoader(\n",
    "        dataset=dataset_train, batch_size=batch_size, shuffle=True, num_workers=4\n",
    "    )\n",
    "    loader_val = DataLoader(\n",
    "        dataset=dataset_val, batch_size=batch_size, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    print(f\"# of training samples: {len(dataset_train)}\")\n",
    "    print(f\"# of validation samples: {len(dataset_val)}\")\n",
    "\n",
    "    net = DnCNN(channels=1, num_of_layers=num_of_layers)\n",
    "    net.apply(weights_init_kaiming)\n",
    "    criterion = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    model = nn.DataParallel(net).cuda()\n",
    "    criterion.cuda()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    writer = SummaryWriter(logdir)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        current_lr = lr if epoch < milestone else lr / 10.0\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = current_lr\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Learning Rate: {current_lr}\")\n",
    "\n",
    "        # Training phase\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (noisy_img, clean_img) in enumerate(loader_train):\n",
    "            noisy_img, clean_img = noisy_img.cuda(), clean_img.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output = net(noisy_img)\n",
    "            loss = criterion(output, clean_img)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if (i + 1) % 100 == 0:  # Print every 100 batches\n",
    "                print(f\"Batch {i+1}, Loss: {running_loss / (i + 1)}\")\n",
    "\n",
    "        # Log training loss\n",
    "        writer.add_scalar(\"Loss/train\", running_loss / len(loader_train), epoch)\n",
    "\n",
    "        # Validation phase\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            psnr = 0.0\n",
    "            for i, (noisy_img, clean_img) in enumerate(loader_val):\n",
    "                noisy_img, clean_img = noisy_img.cuda(), clean_img.cuda()\n",
    "\n",
    "                output = net(noisy_img)\n",
    "                psnr += batch_PSNR(output, clean_img, scale=1)\n",
    "\n",
    "            avg_psnr = psnr / len(dataset_val)\n",
    "            print(f\"Validation PSNR: {avg_psnr}\")\n",
    "\n",
    "            # Log validation PSNR\n",
    "            writer.add_scalar(\"PSNR/val\", avg_psnr, epoch)\n",
    "\n",
    "        # Save the model checkpoint\n",
    "        if (epoch + 1) % 10 == 0:  # Save every 10 epochs\n",
    "            checkpoint_path = f\"{logdir}/model_epoch_{epoch + 1}.pth\"\n",
    "            torch.save(net.state_dict(), checkpoint_path)\n",
    "            print(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "\n",
    "    writer.close()\n",
    "    print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process training data\n",
      "File: data/train/test_001.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_001.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_001.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_001.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_002.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_002.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_002.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_002.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_003.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_003.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_003.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_003.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_004.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_004.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_004.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_004.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_005.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_005.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_005.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_005.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_006.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_006.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_006.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_006.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_007.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_007.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_007.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_007.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_008.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_008.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_008.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_008.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_009.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_009.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_009.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_009.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_010.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_010.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_010.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_010.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_011.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_011.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_011.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_011.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_012.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_012.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_012.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_012.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_013.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_013.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_013.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_013.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_014.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_014.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_014.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_014.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_015.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_015.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_015.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_015.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_016.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_016.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_016.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_016.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_017.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_017.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_017.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_017.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_018.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_018.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_018.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_018.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_019.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_019.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_019.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_019.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_020.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_020.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_020.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_020.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_021.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_021.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_021.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_021.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_022.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_022.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_022.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_022.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_023.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_023.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_023.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_023.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_024.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_024.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_024.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_024.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_025.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_025.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_025.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_025.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_026.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_026.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_026.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_026.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_027.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_027.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_027.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_027.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_028.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_028.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_028.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_028.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_029.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_029.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_029.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_029.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_030.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_030.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_030.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_030.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_031.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_031.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_031.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_031.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_032.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_032.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_032.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_032.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_033.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_033.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_033.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_033.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_034.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_034.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_034.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_034.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_035.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_035.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_035.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_035.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_036.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_036.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_036.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_036.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_037.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_037.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_037.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_037.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_038.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_038.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_038.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_038.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_039.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_039.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_039.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_039.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_040.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_040.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_040.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_040.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_081.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_081.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_081.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_081.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_082.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_082.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_082.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_082.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_083.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_083.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_083.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_083.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_084.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_084.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_084.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_084.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_085.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_085.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_085.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_085.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_086.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_086.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_086.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_086.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_087.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_087.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_087.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_087.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_088.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_088.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_088.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_088.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_089.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_089.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_089.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_089.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_090.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_090.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_090.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_090.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_091.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_091.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_091.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_091.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_092.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_092.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_092.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_092.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_093.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_093.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_093.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_093.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_094.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_094.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_094.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_094.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_095.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_095.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_095.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_095.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_096.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_096.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_096.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_096.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_097.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_097.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_097.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_097.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_098.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_098.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_098.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_098.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_099.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_099.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_099.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_099.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_100.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_100.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_100.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_100.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_101.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_101.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_101.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_101.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_102.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_102.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_102.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_102.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_103.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_103.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_103.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_103.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_104.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_104.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_104.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_104.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_105.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_105.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_105.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_105.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_106.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_106.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_106.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_106.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_107.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_107.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_107.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_107.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_108.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_108.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_108.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_108.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_109.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_109.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_109.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_109.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_110.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_110.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_110.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_110.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_111.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_111.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_111.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_111.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_112.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_112.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_112.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_112.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_113.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_113.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_113.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_113.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_114.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_114.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_114.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_114.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_115.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_115.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_115.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_115.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_116.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_116.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_116.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_116.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_117.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_117.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_117.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_117.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_118.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_118.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_118.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_118.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_119.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_119.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_119.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_119.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_120.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_120.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_120.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_120.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_121.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_121.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_121.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_121.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_122.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_122.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_122.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_122.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_123.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_123.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_123.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_123.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_124.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_124.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_124.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_124.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_125.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_125.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_125.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_125.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_126.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_126.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_126.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_126.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_127.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_127.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_127.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_127.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_128.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_128.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_128.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_128.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_129.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_129.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_129.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_129.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_130.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_130.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_130.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_130.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_131.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_131.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_131.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_131.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_132.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_132.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_132.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_132.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_133.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_133.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_133.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_133.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_134.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_134.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_134.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_134.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_135.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_135.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_135.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_135.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_136.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_136.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_136.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_136.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_137.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_137.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_137.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_137.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_138.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_138.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_138.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_138.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_139.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_139.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_139.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_139.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_140.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_140.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_140.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_140.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_141.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_141.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_141.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_141.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_142.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_142.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_142.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_142.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_143.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_143.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_143.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_143.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_144.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_144.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_144.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_144.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_145.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_145.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_145.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_145.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_146.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_146.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_146.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_146.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_147.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_147.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_147.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_147.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_148.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_148.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_148.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_148.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_149.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_149.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_149.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_149.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_150.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_150.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_150.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_150.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_151.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_151.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_151.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_151.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_152.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_152.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_152.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_152.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_153.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_153.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_153.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_153.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_154.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_154.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_154.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_154.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_155.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_155.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_155.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_155.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_156.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_156.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_156.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_156.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_157.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_157.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_157.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_157.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_158.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_158.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_158.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_158.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_159.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_159.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_159.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_159.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_160.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_160.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_160.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_160.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_161.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_161.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_161.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_161.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_162.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_162.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_162.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_162.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_163.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_163.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_163.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_163.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_164.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_164.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_164.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_164.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_165.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_165.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_165.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_165.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_166.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_166.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_166.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_166.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_167.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_167.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_167.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_167.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_168.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_168.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_168.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_168.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_169.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_169.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_169.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_169.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_170.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_170.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_170.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_170.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_171.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_171.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_171.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_171.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_172.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_172.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_172.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_172.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_173.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_173.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_173.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_173.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_174.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_174.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_174.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_174.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_175.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_175.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_175.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_175.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_176.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_176.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_176.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_176.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_177.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_177.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_177.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_177.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_178.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_178.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_178.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_178.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_179.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_179.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_179.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_179.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_180.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_180.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_180.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_180.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_181.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_181.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_181.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_181.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_182.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_182.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_182.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_182.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_183.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_183.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_183.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_183.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_184.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_184.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_184.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_184.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_185.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_185.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_185.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_185.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_186.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_186.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_186.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_186.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_187.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_187.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_187.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_187.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_188.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_188.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_188.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_188.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_189.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_189.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_189.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_189.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_190.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_190.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_190.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_190.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_191.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_191.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_191.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_191.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_192.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_192.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_192.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_192.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_193.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_193.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_193.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_193.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_194.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_194.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_194.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_194.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_195.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_195.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_195.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_195.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_196.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_196.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_196.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_196.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_197.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_197.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_197.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_197.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_198.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_198.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_198.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_198.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_199.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_199.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_199.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_199.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_200.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_200.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_200.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_200.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_201.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_201.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_201.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_201.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_202.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_202.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_202.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_202.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_203.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_203.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_203.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_203.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_204.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_204.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_204.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_204.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_205.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_205.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_205.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_205.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_206.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_206.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_206.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_206.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_207.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_207.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_207.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_207.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_208.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_208.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_208.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_208.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_209.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_209.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_209.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_209.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_210.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_210.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_210.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_210.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_211.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_211.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_211.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_211.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_212.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_212.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_212.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_212.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_213.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_213.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_213.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_213.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_214.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_214.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_214.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_214.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_215.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_215.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_215.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_215.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_216.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_216.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_216.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_216.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_217.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_217.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_217.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_217.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_218.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_218.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_218.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_218.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_219.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_219.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_219.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_219.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_220.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_220.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_220.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_220.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_221.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_221.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_221.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_221.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_222.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_222.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_222.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_222.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_223.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_223.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_223.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_223.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_224.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_224.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_224.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_224.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_225.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_225.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_225.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_225.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_226.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_226.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_226.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_226.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_227.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_227.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_227.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_227.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_228.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_228.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_228.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_228.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_229.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_229.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_229.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_229.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_230.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_230.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_230.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_230.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_231.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_231.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_231.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_231.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_232.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_232.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_232.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_232.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_233.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_233.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_233.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_233.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_234.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_234.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_234.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_234.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_235.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_235.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_235.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_235.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_236.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_236.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_236.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_236.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_237.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_237.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_237.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_237.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_238.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_238.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_238.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_238.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_239.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_239.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_239.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_239.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_240.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_240.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_240.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_240.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_241.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_241.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_241.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_241.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_242.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_242.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_242.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_242.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_243.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_243.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_243.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_243.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_244.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_244.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_244.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_244.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_245.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_245.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_245.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_245.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_246.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_246.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_246.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_246.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_247.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_247.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_247.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_247.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_248.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_248.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_248.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_248.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_249.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_249.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_249.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_249.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_250.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_250.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_250.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_250.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_251.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_251.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_251.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_251.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_252.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_252.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_252.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_252.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_253.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_253.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_253.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_253.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_254.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_254.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_254.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_254.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_255.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_255.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_255.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_255.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_256.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_256.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_256.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_256.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_257.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_257.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_257.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_257.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_258.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_258.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_258.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_258.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_259.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_259.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_259.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_259.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_260.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_260.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_260.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_260.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_261.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_261.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_261.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_261.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_262.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_262.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_262.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_262.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_263.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_263.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_263.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_263.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_264.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_264.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_264.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_264.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_265.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_265.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_265.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_265.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_266.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_266.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_266.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_266.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_267.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_267.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_267.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_267.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_268.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_268.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_268.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_268.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_269.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_269.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_269.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_269.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_270.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_270.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_270.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_270.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_271.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_271.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_271.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_271.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_272.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_272.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_272.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_272.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_273.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_273.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_273.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_273.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_274.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_274.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_274.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_274.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_275.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_275.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_275.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_275.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_276.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_276.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_276.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_276.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_277.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_277.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_277.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_277.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_278.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_278.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_278.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_278.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_279.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_279.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_279.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_279.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_280.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_280.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_280.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_280.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_281.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_281.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_281.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_281.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_282.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_282.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_282.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_282.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_283.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_283.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_283.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_283.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_284.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_284.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_284.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_284.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_285.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_285.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_285.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_285.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_286.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_286.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_286.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_286.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_287.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_287.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_287.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_287.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_288.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_288.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_288.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_288.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_289.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_289.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_289.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_289.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_290.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_290.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_290.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_290.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_291.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_291.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_291.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_291.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_292.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_292.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_292.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_292.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_293.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_293.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_293.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_293.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_294.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_294.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_294.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_294.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_295.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_295.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_295.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_295.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_296.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_296.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_296.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_296.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_297.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_297.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_297.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_297.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_298.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_298.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_298.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_298.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_299.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_299.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_299.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_299.png Scale 0.7 # samples: 81\n",
      "File: data/train/test_300.png Scale 1.0 # samples: 225\n",
      "File: data/train/test_300.png Scale 0.9 # samples: 169\n",
      "File: data/train/test_300.png Scale 0.8 # samples: 121\n",
      "File: data/train/test_300.png Scale 0.7 # samples: 81\n",
      "\n",
      "Process validation data\n",
      "File: data/Set12/01.png\n",
      "File: data/Set12/02.png\n",
      "File: data/Set12/03.png\n",
      "File: data/Set12/04.png\n",
      "File: data/Set12/05.png\n",
      "File: data/Set12/06.png\n",
      "File: data/Set12/07.png\n",
      "File: data/Set12/08.png\n",
      "File: data/Set12/09.png\n",
      "File: data/Set12/10.png\n",
      "File: data/Set12/11.png\n",
      "File: data/Set12/12.png\n",
      "Training set, # samples 154960\n",
      "\n",
      "Validation set, # samples 12\n",
      "\n",
      "Loading dataset ...\n",
      "# of training samples: 172\n",
      "# of validation samples: 78\n",
      "Epoch 1, Learning Rate: 0.001\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 5.62 GiB total capacity; 149.92 MiB already allocated; 36.50 MiB free; 160.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_dncnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_of_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m17\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmilestone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoiseL\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_noiseL\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 87\u001b[0m, in \u001b[0;36mtrain_dncnn\u001b[0;34m(preprocess, batch_size, num_of_layers, epochs, lr, milestone, noiseL, val_noiseL, logdir)\u001b[0m\n\u001b[1;32m     84\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, clean_img)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/dinov2/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 43\u001b[0m, in \u001b[0;36mDnCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdncnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/dinov2/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/dinov2/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/dinov2/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/dinov2/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/dinov2/lib/python3.10/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 5.62 GiB total capacity; 149.92 MiB already allocated; 36.50 MiB free; 160.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "train_dncnn(\n",
    "    preprocess=True,\n",
    "    batch_size=2,\n",
    "    num_of_layers=17,\n",
    "    epochs=10,\n",
    "    lr=1e-3,\n",
    "    milestone=30,\n",
    "    noiseL=25,\n",
    "    val_noiseL=25,\n",
    "    logdir=\"logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    return data / 255.0\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Define or import your DnCNN model here\n",
    "class DnCNN(nn.Module):\n",
    "    # Define the model architecture here\n",
    "    pass\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    return data / 255.0\n",
    "\n",
    "\n",
    "def batch_PSNR(output, target, max_val):\n",
    "    mse = F.mse_loss(output, target, reduction=\"mean\")\n",
    "    psnr = 10 * torch.log10((max_val**2) / mse)\n",
    "    return psnr.item()\n",
    "\n",
    "\n",
    "def test_dncnn(test_data=\"Set12\", num_of_layers=17, logdir=\"logs\"):\n",
    "    print(\"Loading model ...\")\n",
    "    net = DnCNN(channels=1, num_of_layers=num_of_layers)\n",
    "    model = net.cuda()\n",
    "    model.load_state_dict(torch.load(os.path.join(logdir, \"model_epoch_10.pth\")))\n",
    "    model.eval()\n",
    "\n",
    "    # Paths for clean and noisy images\n",
    "    clean_folder = (\n",
    "        \"/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/clean\"\n",
    "    )\n",
    "    noisy_folder = (\n",
    "        \"/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy\"\n",
    "    )\n",
    "\n",
    "    print(\"Loading data info ...\")\n",
    "    # Match multiple image file extensions\n",
    "    file_patterns = [\n",
    "        os.path.join(noisy_folder, f\"*.{ext}\") for ext in [\"png\", \"jpeg\", \"jpg\", \"bmp\"]\n",
    "    ]\n",
    "    noisy_files = []\n",
    "    for pattern in file_patterns:\n",
    "        noisy_files.extend(glob.glob(pattern))\n",
    "    noisy_files.sort()\n",
    "\n",
    "    psnr_test = 0\n",
    "    num_images = len(noisy_files)\n",
    "\n",
    "    for f in noisy_files:\n",
    "        filename = os.path.basename(f)\n",
    "        clean_file = os.path.join(clean_folder, filename)\n",
    "\n",
    "        # Load noisy image\n",
    "        Img_noisy = cv2.imread(f)\n",
    "        if Img_noisy is None:\n",
    "            print(f\"Failed to load noisy image {f}\")\n",
    "            continue\n",
    "\n",
    "        # Convert color image to grayscale if necessary\n",
    "        if Img_noisy.ndim == 3 and Img_noisy.shape[2] == 3:\n",
    "            Img_noisy = cv2.cvtColor(Img_noisy, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        Img_noisy = normalize(np.float32(Img_noisy))\n",
    "        Img_noisy = np.expand_dims(Img_noisy, 0)  # Add channel dimension\n",
    "        Img_noisy = np.expand_dims(Img_noisy, 1)  # Add batch dimension\n",
    "        INoisy = torch.Tensor(Img_noisy)\n",
    "\n",
    "        # Load clean image\n",
    "        Img_clean = cv2.imread(clean_file)\n",
    "        if Img_clean is None:\n",
    "            print(f\"Failed to load clean image {clean_file}\")\n",
    "            continue\n",
    "\n",
    "        # Convert color image to grayscale if necessary\n",
    "        if Img_clean.ndim == 3 and Img_clean.shape[2] == 3:\n",
    "            Img_clean = cv2.cvtColor(Img_clean, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        Img_clean = normalize(np.float32(Img_clean))\n",
    "        Img_clean = np.expand_dims(Img_clean, 0)  # Add channel dimension\n",
    "        Img_clean = np.expand_dims(Img_clean, 1)  # Add batch dimension\n",
    "        ISource = torch.Tensor(Img_clean)\n",
    "\n",
    "        ISource, INoisy = Variable(ISource.cuda()), Variable(INoisy.cuda())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            Out = torch.clamp(INoisy - model(INoisy), 0.0, 1.0)\n",
    "        psnr = batch_PSNR(Out, ISource, 1.0)\n",
    "        psnr_test += psnr\n",
    "        print(f\"{f} PSNR: {psnr:.4f}\")\n",
    "\n",
    "    psnr_test /= num_images\n",
    "    print(f\"\\nPSNR on test data: {psnr_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n",
      "Loading data info ...\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/10.bmp PSNR: 3.9288\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/11.bmp PSNR: 3.9405\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/15.bmp PSNR: 3.9342\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/2.bmp PSNR: 3.8386\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/22.bmp PSNR: 3.9601\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/25.bmp PSNR: 4.1138\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/26.bmp PSNR: 4.1535\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/29.bmp PSNR: 4.2138\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/31.bmp PSNR: 4.0201\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/35.bmp PSNR: 4.0466\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/37.bmp PSNR: 4.3730\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/39.bmp PSNR: 4.2920\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/4.bmp PSNR: 3.9001\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/41.bmp PSNR: 4.5651\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/43.bmp PSNR: 4.5792\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/45.bmp PSNR: 3.7933\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/48.bmp PSNR: 3.8355\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/49.bmp PSNR: 3.8302\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/51.bmp PSNR: 3.7961\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/52.bmp PSNR: 3.8014\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/6.bmp PSNR: 3.8527\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/9.bmp PSNR: 3.9149\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0100.jpg PSNR: 3.8395\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0103.jpg PSNR: 3.9612\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0105.jpg PSNR: 3.9385\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0107.jpg PSNR: 3.8956\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0108.jpg PSNR: 3.8967\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0109.jpg PSNR: 3.8708\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0110.jpg PSNR: 3.8820\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0111.jpg PSNR: 3.8480\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0113.jpg PSNR: 3.8426\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0114.jpg PSNR: 3.9240\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0115.jpg PSNR: 4.0428\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0117.jpg PSNR: 4.1179\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0118.jpg PSNR: 4.1346\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0119.jpg PSNR: 4.1860\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0121.jpg PSNR: 3.8709\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0122.jpg PSNR: 4.1737\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0124.jpg PSNR: 3.9991\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0125.jpg PSNR: 4.0176\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0130.jpg PSNR: 3.8904\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0131.jpg PSNR: 4.4097\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0133.jpg PSNR: 4.5963\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0134.jpg PSNR: 3.8706\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0135.jpg PSNR: 3.7991\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0144.jpg PSNR: 3.9074\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0202.jpg PSNR: 3.9607\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0205.jpg PSNR: 3.9711\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0209.jpg PSNR: 3.9095\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0211.jpg PSNR: 3.8650\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0212.jpg PSNR: 3.9144\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0213.jpg PSNR: 3.8648\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0218.jpg PSNR: 4.2322\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0219.jpg PSNR: 4.3089\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0220.jpg PSNR: 4.2845\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0221.jpg PSNR: 3.8851\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0226.jpg PSNR: 4.1931\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0229.jpg PSNR: 4.2169\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0231.jpg PSNR: 4.4350\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0232.jpg PSNR: 4.5893\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0236.jpg PSNR: 3.8172\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0237.jpg PSNR: 3.8181\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0239.jpg PSNR: 3.8801\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0240.jpg PSNR: 3.8148\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0241.jpg PSNR: 3.8258\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0242.jpg PSNR: 3.8789\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0243.jpg PSNR: 3.8351\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0244.jpg PSNR: 3.9435\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0248.jpg PSNR: 3.9378\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0252.jpg PSNR: 3.9266\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0253.jpg PSNR: 3.8997\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0254.jpg PSNR: 3.9143\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0255.jpg PSNR: 3.8776\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0259.jpg PSNR: 3.8574\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0260.jpg PSNR: 3.8959\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0266.jpg PSNR: 4.2401\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0276.jpg PSNR: 3.8693\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0277.jpg PSNR: 4.4128\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0278.jpg PSNR: 4.5657\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0280.jpg PSNR: 3.8608\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0288.jpg PSNR: 3.8714\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0289.jpg PSNR: 3.8310\n",
      "/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy/image_0290.jpg PSNR: 3.9330\n",
      "\n",
      "PSNR on test data: 4.0113\n"
     ]
    }
   ],
   "source": [
    "test_dncnn(\n",
    "    test_data=\"/home/kareem/hacking/research/AI_Love/denoising/noise2noise_data/test/noisy\",  # The directory containing your test images\n",
    "    num_of_layers=17,  # The number of layers in your DnCNN model\n",
    "    logdir=\"./logs\",  # The directory where your model weights are saved\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
