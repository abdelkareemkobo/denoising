{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "import cv2\n",
    "import glob\n",
    "import torch.utils.data as udata\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.kaiming_normal(m.weight.data, a=0, mode=\"fan_in\")\n",
    "    elif classname.find(\"Linear\") != -1:\n",
    "        nn.init.kaiming_normal(m.weight.data, a=0, mode=\"fan_in\")\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        # nn.init.uniform(m.weight.data, 1.0, 0.02)\n",
    "        m.weight.data.normal_(mean=0, std=math.sqrt(2.0 / 9.0 / 64.0)).clamp_(\n",
    "            -0.025, 0.025\n",
    "        )\n",
    "        nn.init.constant(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_PSNR(img,imclean,data_range):\n",
    "    Img = img.data.cpu().numpy().astype(np.float32)\n",
    "    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n",
    "    PSNR =0 \n",
    "    for i in range(Img.shape[0]):\n",
    "        PSNR += peak_signal_noise_ratio(Iclean[i,:,:,:],Img[i,:,:,:],data_range=data_range)\n",
    "    return (PSNR/Img.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(image, mode):\n",
    "    out = np.transpose(image, (1,2,0))\n",
    "    if mode == 0:\n",
    "        # original\n",
    "        out = out\n",
    "    elif mode == 1:\n",
    "        # flip up and down\n",
    "        out = np.flipud(out)\n",
    "    elif mode == 2:\n",
    "        # rotate counterwise 90 degree\n",
    "        out = np.rot90(out)\n",
    "    elif mode == 3:\n",
    "        # rotate 90 degree and flip up and down\n",
    "        out = np.rot90(out)\n",
    "        out = np.flipud(out)\n",
    "    elif mode == 4:\n",
    "        # rotate 180 degree\n",
    "        out = np.rot90(out, k=2)\n",
    "    elif mode == 5:\n",
    "        # rotate 180 degree and flip\n",
    "        out = np.rot90(out, k=2)\n",
    "        out = np.flipud(out)\n",
    "    elif mode == 6:\n",
    "        # rotate 270 degree\n",
    "        out = np.rot90(out, k=3)\n",
    "    elif mode == 7:\n",
    "        # rotate 270 degree and flip\n",
    "        out = np.rot90(out, k=3)\n",
    "        out = np.flipud(out)\n",
    "    return np.transpose(out, (2,0,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, channels, num_of_layers=17, dropout_prob=0.2):\n",
    "        super(DnCNN, self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        features = 64\n",
    "        layers = []\n",
    "\n",
    "        # First Conv layer without dropout\n",
    "        layers.append(\n",
    "            nn.Conv2d(\n",
    "                in_channels=channels,\n",
    "                out_channels=features,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=padding,\n",
    "                bias=False,\n",
    "            )\n",
    "        )\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        # Intermediate layers with dropout\n",
    "        for _ in range(num_of_layers - 2):\n",
    "            layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=features,\n",
    "                    out_channels=features,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding=padding,\n",
    "                    bias=False,\n",
    "                )\n",
    "            )\n",
    "            layers.append(nn.BatchNorm2d(features))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "            # Adding dropout after each ReLU\n",
    "            layers.append(nn.Dropout(p=dropout_prob))\n",
    "\n",
    "        # Last Conv layer without dropout\n",
    "        layers.append(\n",
    "            nn.Conv2d(\n",
    "                in_channels=features,\n",
    "                out_channels=channels,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=padding,\n",
    "                bias=False,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.dncnn = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.dncnn(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    return data/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(udata.Dataset):\n",
    "    def __init__(self, clean_dir, noisy_dir):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.clean_files = sorted(\n",
    "            glob.glob(os.path.join(clean_dir, \"*.png\"))\n",
    "        )  # Free noise images\n",
    "        self.noisy_files = sorted(\n",
    "            glob.glob(os.path.join(noisy_dir, \"*.png\"))\n",
    "        )  # Noisy images\n",
    "        assert len(self.clean_files) == len(\n",
    "            self.noisy_files\n",
    "        ), \"Mismatch between clean and noisy images count\"\n",
    "        random.shuffle(\n",
    "            self.clean_files\n",
    "        )  # Shuffle the clean files list, which will be used as reference\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.clean_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        clean_img_path = self.clean_files[index]\n",
    "        noisy_img_path = self.noisy_files[index]\n",
    "\n",
    "        # Load clean and noisy images\n",
    "        clean_img = cv2.imread(\n",
    "            clean_img_path, cv2.IMREAD_GRAYSCALE\n",
    "        )  # Load clean image (grayscale)\n",
    "        noisy_img = cv2.imread(\n",
    "            noisy_img_path, cv2.IMREAD_GRAYSCALE\n",
    "        )  # Load noisy image (grayscale)\n",
    "\n",
    "        # Normalize images\n",
    "        clean_img = np.float32(normalize(clean_img))\n",
    "        noisy_img = np.float32(normalize(noisy_img))\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        clean_img = torch.Tensor(clean_img).unsqueeze(0)  # Add channel dimension\n",
    "        noisy_img = torch.Tensor(noisy_img).unsqueeze(0)  # Add channel dimension\n",
    "\n",
    "        return clean_img, noisy_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "outf= \"./logs\"\n",
    "mode = \"S\"\n",
    "noiseL = 50\n",
    "val_noiseL = 25\n",
    "batchSize = 6\n",
    "num_of_layers = 17\n",
    "lr = 1e-3\n",
    "epochs=5\n",
    "milestone = 30\n",
    "clean_dir = \"/home/kareem/hacking/research/AI_Love/denoising/DcNN/data/train\"\n",
    "noisy_dir = \"/home/kareem/hacking/research/AI_Love/denoising/DcNN/data/noisy_train\"\n",
    "test_clean_dir = \"/home/kareem/hacking/research/AI_Love/denoising/DcNN/data/test\"\n",
    "test_noisy_dir = \"/home/kareem/hacking/research/AI_Love/denoising/DcNN/data/noisy_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset ...\n",
      "\n",
      "# of training samples: 260\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_269732/3161319601.py:4: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data, a=0, mode=\"fan_in\")\n",
      "/tmp/ipykernel_269732/3161319601.py:12: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(m.bias.data, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "print(\"Loading dataset ...\\n\")\n",
    "\n",
    "\n",
    "dataset_train = Dataset(clean_dir=clean_dir,noisy_dir=noisy_dir)\n",
    "loader_train = DataLoader(\n",
    "    dataset=dataset_train, num_workers=4, batch_size=batchSize, shuffle=True\n",
    ")\n",
    "print(\"# of training samples: %d\\n\" % int(len(dataset_train)))\n",
    "# Build model\n",
    "net = DnCNN(channels=1, num_of_layers=num_of_layers,dropout_prob=0.3)\n",
    "net.apply(weights_init_kaiming)\n",
    "criterion = nn.MSELoss(size_average=False)\n",
    "# Move to GPU\n",
    "device_ids = [0]\n",
    "model = nn.DataParallel(net, device_ids=device_ids).cuda()\n",
    "criterion.cuda()\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=1e-4)\n",
    "# training\n",
    "writer = SummaryWriter(outf)\n",
    "step = 0\n",
    "noiseL_B = [0, 55]  # ingnored when opt.mode=='S'\n",
    "psnr_val = 0\n",
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.001000\n",
      "[epoch 1][1/44] loss: 1149.3796 PSNR_train: 11.7420\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     31\u001b[0m out_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(noisy_img \u001b[38;5;241m-\u001b[39m model(noisy_img), \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m psnr_train \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_PSNR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[epoch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m][\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m] loss: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m PSNR_train: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;241m%\u001b[39m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(loader_train), loss\u001b[38;5;241m.\u001b[39mitem(), psnr_train)\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Log the scalar values\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m, in \u001b[0;36mbatch_PSNR\u001b[0;34m(img, imclean, data_range)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_PSNR\u001b[39m(img,imclean,data_range):\n\u001b[0;32m----> 2\u001b[0m     Img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      3\u001b[0m     Iclean \u001b[38;5;241m=\u001b[39m imclean\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      4\u001b[0m     PSNR \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "for epoch in range(epochs):\n",
    "    if epoch < milestone:\n",
    "        current_lr = lr\n",
    "    else:\n",
    "        current_lr = lr / 10.0\n",
    "    # set learning rate\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = current_lr\n",
    "    print(\"learning rate %f\" % current_lr)\n",
    "\n",
    "    # train\n",
    "    for i, (clean_img, noisy_img) in enumerate(loader_train, 0):\n",
    "        # training step\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        clean_img, noisy_img = Variable(clean_img.cuda()), Variable(noisy_img.cuda())\n",
    "\n",
    "        out_train = model(noisy_img)\n",
    "        noise = (\n",
    "            noisy_img - clean_img\n",
    "        )  # The difference between noisy and clean is the noise\n",
    "        loss = criterion(out_train, noise) / (noisy_img.size()[0] * 2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # results\n",
    "        model.eval()\n",
    "        out_train = torch.clamp(noisy_img - model(noisy_img), 0.0, 1.0)\n",
    "        psnr_train = batch_PSNR(out_train, clean_img, 1.0)\n",
    "        print(\n",
    "            \"[epoch %d][%d/%d] loss: %.4f PSNR_train: %.4f\"\n",
    "            % (epoch + 1, i + 1, len(loader_train), loss.item(), psnr_train)\n",
    "        )\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            # Log the scalar values\n",
    "            writer.add_scalar(\"loss\", loss.item(), step)\n",
    "            writer.add_scalar(\"PSNR on training data\", psnr_train, step)\n",
    "        step += 1\n",
    "    # save model\n",
    "    torch.save(model.state_dict(), os.path.join(outf, \"net.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_269732/3193723546.py:10: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  clean_img, noisy_img = Variable(clean_img.cuda(), volatile=True), Variable(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psnre_val 11.865729423230693\n",
      "psnre_val 12.802597219245737\n",
      "psnre_val 13.926203857751673\n",
      "psnre_val 16.715856226095987\n",
      "psnre_val 12.926392920142327\n",
      "psnre_val 9.574606302899324\n",
      "psnre_val 10.996847642440475\n",
      "psnre_val 13.353520930891767\n",
      "psnre_val 11.97394551184109\n",
      "psnre_val 10.464963214855672\n",
      "psnre_val 13.035174016090822\n",
      "psnre_val 13.683507843862499\n",
      "psnre_val 12.25830511611088\n",
      "psnre_val 11.099776019629966\n",
      "psnre_val 12.402361209628479\n",
      "psnre_val 11.18130648139553\n",
      "psnre_val 5.34362122434932\n",
      "psnre_val 12.026570248244628\n",
      "psnre_val 13.588167894701499\n",
      "psnre_val 10.780811771280039\n",
      "psnre_val 11.90709348708676\n",
      "psnre_val 13.185305840941934\n",
      "psnre_val 8.98746688537217\n",
      "psnre_val 11.095027993201573\n",
      "psnre_val 8.287523943121325\n",
      "psnre_val 11.40396061409627\n",
      "psnre_val 12.298201121418469\n",
      "psnre_val 11.896795591622151\n",
      "psnre_val 10.041518580716955\n",
      "psnre_val 11.920560544841239\n",
      "psnre_val 12.307291770083655\n",
      "psnre_val 13.204762109610805\n",
      "psnre_val 10.016509421361059\n",
      "psnre_val 10.589096062972514\n",
      "psnre_val 11.280493110834659\n",
      "psnre_val 10.904722843796753\n",
      "psnre_val 12.686463310501237\n",
      "psnre_val 9.750305034955195\n",
      "psnre_val 13.846055348337693\n",
      "psnre_val 8.031070838325338\n",
      "psnre_val 10.867397668751979\n",
      "psnre_val 12.569180609849065\n",
      "psnre_val 14.317199600476851\n",
      "psnre_val 12.318226800763696\n",
      "psnre_val 14.665371401524002\n",
      "psnre_val 15.496853131081295\n",
      "psnre_val 8.211750667151492\n",
      "psnre_val 10.660776122432509\n",
      "psnre_val 6.783854993088081\n",
      "psnre_val 11.231952785794546\n",
      "psnre_val 9.85033542224481\n",
      "psnre_val 12.589718249428003\n",
      "psnre_val 11.013852182099575\n",
      "psnre_val 11.742964900171117\n",
      "psnre_val 12.57121039559479\n",
      "psnre_val 12.49896607822808\n",
      "psnre_val 8.037584404855853\n",
      "psnre_val 15.282479530417989\n",
      "psnre_val 6.741201088209853\n",
      "psnre_val 11.418690259126311\n",
      "psnre_val 10.479998240855249\n",
      "psnre_val 7.793048704703606\n",
      "psnre_val 10.40251459359002\n",
      "psnre_val 8.239484351957163\n",
      "psnre_val 12.947483068520496\n",
      "psnre_val 9.798311669913613\n",
      "psnre_val 11.593945622228896\n",
      "psnre_val 11.080922060558379\n",
      "psnre_val 11.657044884438132\n",
      "psnre_val 9.918614426962604\n",
      "psnre_val 10.137593624570172\n",
      "psnre_val 12.33637976687762\n",
      "psnre_val 12.296341587300523\n",
      "psnre_val 9.417284005009675\n",
      "psnre_val 8.238054008735572\n",
      "psnre_val 7.4746217821280165\n",
      "psnre_val 10.530239080257536\n",
      "psnre_val 10.52990743313531\n",
      "psnre_val 9.650605357770615\n",
      "psnre_val 9.017785610748799\n",
      "psnre_val 12.099216413042617\n",
      "psnre_val 9.402261824745022\n",
      "psnre_val 12.788426247969442\n",
      "psnre_val 11.84479388621709\n",
      "psnre_val 11.50233124714375\n",
      "psnre_val 11.064756523781023\n",
      "psnre_val 11.390346892560226\n",
      "psnre_val 10.119399164629343\n",
      "psnre_val 12.09249787041342\n",
      "psnre_val 12.918623666640626\n",
      "psnre_val 11.859403527502124\n",
      "psnre_val 13.138438054448363\n",
      "psnre_val 12.921981872720725\n",
      "psnre_val 11.854795985071451\n",
      "psnre_val 9.809898429807298\n",
      "psnre_val 12.267630089963042\n",
      "psnre_val 14.425669852662747\n",
      "psnre_val 9.896421222392428\n",
      "psnre_val 17.40854992717407\n",
      "psnre_val 10.914151869327055\n",
      "Final PSNR 11.3576983026765\n"
     ]
    }
   ],
   "source": [
    "dataset_val = Dataset(clean_dir=test_clean_dir, noisy_dir=test_noisy_dir)\n",
    "loader_val = torch.utils.data.DataLoader(dataset_val, batch_size=1, shuffle=False)\n",
    "model.eval()\n",
    "psnr_val = 0\n",
    "for k in range(len(dataset_val)):\n",
    "    clean_img, noisy_img = torch.unsqueeze(dataset_val[k][0], 0), torch.unsqueeze(\n",
    "        dataset_val[k][1], 0\n",
    "    )\n",
    "\n",
    "    clean_img, noisy_img = Variable(clean_img.cuda(), volatile=True), Variable(\n",
    "        noisy_img.cuda(), volatile=True\n",
    "    )\n",
    "\n",
    "    out_val = torch.clamp(noisy_img - model(noisy_img), 0.0, 1.0)\n",
    "    # psnr_val += batch_PSNR(out_val, clean_img, 1.0)\n",
    "    pnsr_e = batch_PSNR(out_val,clean_img,1.0)\n",
    "    print(\"psnre_val\",pnsr_e)\n",
    "    psnr_val += pnsr_e\n",
    "psnr_val /= len(dataset_val)\n",
    "print(\"Final PSNR\",psnr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#! Best value\n",
    "#Final PSNR 12.945157112665747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
